{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nAuthor: Gregor Pfalz\\ngithub: GPawi\\n'"
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Author: Gregor Pfalz\n",
    "github: GPawi\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "#import matplotlib.pyplot as plt\n",
    "#import seaborn as sns\n",
    "#import os\n",
    "#import sys\n",
    "import sqlalchemy\n",
    "import getpass\n",
    "#import datetime\n",
    "from sqlalchemy.exc import IntegrityError\n",
    "from xlrd import XLRDError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [],
   "source": [
    "class connection_db(object):\n",
    "    def __init__(self, core, db = None, password = None, force_upload = False):\n",
    "        self.__core = core\n",
    "        self.__force_upload = force_upload\n",
    "        self.__coreid = core._data_preparation__coreid\n",
    "        if db is not None and password is not None:\n",
    "            self.__db = db\n",
    "            self.__password = password\n",
    "        elif db is None and password is None:\n",
    "            self.__db = input(f'What is the database name in which {self.__coreid} should be inserted? ')\n",
    "            self.__password = getpass.getpass(prompt='What is the password for that database? ')\n",
    "        elif db is not None and password is None:\n",
    "            self.__db = db\n",
    "            self.__password = getpass.getpass(prompt='What is the password for that database? ')\n",
    "        else:\n",
    "            self.__db = input(f'What is the database name in which {self.__coreid} should be inserted? ')\n",
    "            self.__password = password\n",
    "            \n",
    "        self.__engine = sqlalchemy.create_engine(f'postgresql://postgres:{self.__password}@localhost/{self.__db}')\n",
    "        \n",
    "        \n",
    "    def __upload_scientist__(self):\n",
    "        __core = self.__core\n",
    "        __engine = self.__engine\n",
    "        self.__scientist = __core._data_preparation__scientist\n",
    "        self.__scientist_columns = __core._data_preparation__scientist_columns\n",
    "        try:\n",
    "            __con = __engine.connect()\n",
    "            self.__scientist_duplicate_check = pd.merge(self.__scientist, pd.read_sql('scientist', __con), how ='inner', on = self.__scientist_columns)\n",
    "            if any(self.__scientist_duplicate_check.columns == 'scientistid') and (len(self.__scientist_duplicate_check) == len(self.__scientist)):\n",
    "                self.__scientist = self.__scientist_duplicate_check\n",
    "                __con.close()\n",
    "                print ('Scientist(s) already exist!')\n",
    "            elif any(self.__scientist_duplicate_check.columns == 'scientistid') and (len(self.__scientist_duplicate_check) != len(self.__scientist)):\n",
    "                self.__new_scientist = self.__scientist[~self.__scientist.isin(self.__scientist_duplicate_check)].dropna()\n",
    "                self.__new_scientist.to_sql('scientist', __con, if_exists='append', index = False)\n",
    "                self.__scientist_duplicate_check = pd.merge(self.__scientist, pd.read_sql('scientist', __con), how ='inner', on = self.__scientist_columns)\n",
    "                self.__scientist = self.__scientist_duplicate_check\n",
    "                __con.close()\n",
    "                print ('Added new scientist(s)!')\n",
    "            else:\n",
    "                self.__scientist.to_sql('scientist', __con, if_exists='append', index = False)\n",
    "                self.__scientist_duplicate_check = pd.merge(self.__scientist, pd.read_sql('scientist', __con), how ='inner', on = self.__scientist_columns)\n",
    "                self.__scientist = self.__scientist_duplicate_check\n",
    "                __con.close()\n",
    "                print ('All scientist(s) added!')\n",
    "        except:\n",
    "            __con.close()\n",
    "            print ('There was an issue - Please report to Gregor Pfalz (Gregor.Pfalz@awi.de)!')\n",
    "    \n",
    "    def __upload_expedition__(self):\n",
    "        __core = self.__core\n",
    "        __engine = self.__engine\n",
    "        self.__expedition = __core._data_preparation__expedition\n",
    "        self.__expedition_columns = __core._data_preparation__expedition_columns\n",
    "        try:\n",
    "            __con = __engine.connect()\n",
    "            self.__expedition_duplicate_check = pd.merge(self.__expedition, pd.read_sql('expedition', __con), how ='inner', on = self.__expedition_columns)\n",
    "            if len(self.__expedition_duplicate_check) > 0:\n",
    "                self.__expedition = self.__expedition_duplicate_check\n",
    "                __con.close()\n",
    "                print ('Expedition already exists!')\n",
    "            else:\n",
    "                self.__expedition.to_sql('expedition', __con, if_exists='append', index = False)\n",
    "                __con.close()\n",
    "                print ('New expedition added!')\n",
    "        except:\n",
    "            __con.close()\n",
    "            print ('There was an issue - Please report to Gregor Pfalz (Gregor.Pfalz@awi.de)!')\n",
    "        \n",
    "    def __upload_lake__(self):\n",
    "        __core = self.__core\n",
    "        __engine = self.__engine\n",
    "        self.__lake = __core._data_preparation__lake\n",
    "        self.__lake_columns = __core._data_preparation__lake_columns\n",
    "        try:\n",
    "            __con = __engine.connect()\n",
    "            self.__lake_duplicate_check = pd.merge(self.__lake, pd.read_sql('lake', __con), how ='inner', on = self.__lake_columns)\n",
    "            if len(self.__lake_duplicate_check) > 0:\n",
    "                self.__lake = self.__lake_duplicate_check\n",
    "                __con.close()\n",
    "                print ('Lake already exists!')\n",
    "            else:\n",
    "                self.__lake.to_sql('lake', __con, if_exists='append', index = False)\n",
    "                __con.close()\n",
    "                print ('New lake added!')\n",
    "        except:\n",
    "            __con.close()\n",
    "            print ('There was an issue - Please report to Gregor Pfalz (Gregor.Pfalz@awi.de)!')\n",
    "    \n",
    "    def __upload_drilling__(self):\n",
    "        __core = self.__core\n",
    "        __engine = self.__engine\n",
    "        __coreid = self.__coreid\n",
    "        __force_upload = self.__force_upload\n",
    "        self.__drilling = __core._data_preparation__drilling\n",
    "        self.__drilling_columns = __core._data_preparation__drilling_columns\n",
    "        try:\n",
    "            __con = __engine.connect()\n",
    "            self.__drilling_duplicate_check = pd.merge(self.__drilling, pd.read_sql('drilling', __con), how ='inner', on = self.__drilling_columns)\n",
    "            if len(self.__drilling_duplicate_check) > 0:\n",
    "                self.__drilling = self.__drilling_duplicate_check\n",
    "                __con.close()\n",
    "                if __force_upload == False:\n",
    "                    while True:\n",
    "                        self.__upload_query = input(f'Core {__coreid} already exist - Do you still want to continue uploading the data? Y/N? ')\n",
    "                        self.__upload_answer = self.__upload_query[0].lower() \n",
    "                        if self.__upload_query == '' or not self.__upload_answer in ['y','n']:\n",
    "                            print('Please answer with yes or no!') \n",
    "                        else:\n",
    "                            break\n",
    "                    if self.__upload_answer == 'y':\n",
    "                        self.__upload_stop = False\n",
    "                        print ('Ok!')\n",
    "                    if self.__upload_answer == 'n':\n",
    "                        raise Exception('Manually stopped upload process.')\n",
    "                else:\n",
    "                    self.__upload_stop = False\n",
    "                    print (f'Core {__coreid} already exists!')\n",
    "                \n",
    "            else:\n",
    "                self.__drilling.to_sql('drilling', __con, if_exists='append', index = False)\n",
    "                __con.close()\n",
    "                self.__upload_stop = False\n",
    "                print ('New core information added!')\n",
    "        \n",
    "        except Exception:\n",
    "            __con.close()\n",
    "            self.__upload_stop = True\n",
    "            print ('Manually stopped upload process.')\n",
    "        \n",
    "        except:\n",
    "            __con.close()\n",
    "            print ('There was an issue - Please report to Gregor Pfalz (Gregor.Pfalz@awi.de)!')\n",
    "    \n",
    "    def __upload_participant__(self):\n",
    "        self.__participant = self.__scientist\n",
    "        __coreid = self.__coreid\n",
    "        __engine = self.__engine\n",
    "        self.__participant['coreid'] = __coreid\n",
    "        self.__participant = self.__participant[['scientistid','coreid']]\n",
    "        try:\n",
    "            __con = __engine.connect()\n",
    "            self.__participant_duplicate_check = pd.merge(self.__participant, pd.read_sql('participant', __con), how ='inner', on = ['scientistid','coreid'])\n",
    "            if (len(self.__participant_duplicate_check) == len(self.__participant)):\n",
    "                self.__participant = self.__participant_duplicate_check\n",
    "                __con.close()\n",
    "                print ('Participant(s) already registered!')\n",
    "            elif (len(self.__participant_duplicate_check) != len(self.__participant)):\n",
    "                self.__new_participant = self.__participant[~self.__participant.isin(self.__participant_duplicate_check)].dropna()\n",
    "                self.__new_participant.to_sql('participant', __con, if_exists='append', index = False)\n",
    "                self.__participant_duplicate_check = pd.merge(self.__participant, pd.read_sql('participant', __con), how ='inner', on = ['scientistid','coreid'])\n",
    "                self.__participant = self.__participant_duplicate_check\n",
    "                __con.close()\n",
    "                print (f'Added new participant(s) to {__coreid}!')\n",
    "            else:\n",
    "                self.__participant.to_sql('participant', __con, if_exists='append', index = False)\n",
    "                self.__participant_duplicate_check = pd.merge(self.__participant, pd.read_sql('participant', __con), how ='inner', on = ['scientistid','coreid'])\n",
    "                self.__participant = self.__participant_duplicate_check\n",
    "                __con.close()\n",
    "                print (f'Participant(s) added for {__coreid}!')\n",
    "        except:\n",
    "            __con.close()\n",
    "            print ('There was an issue - Please report to Gregor Pfalz (Gregor.Pfalz@awi.de)!')\n",
    "    \n",
    "    def __upload_organic__(self): \n",
    "        __core = self.__core\n",
    "        __coreid = self.__coreid\n",
    "        __engine = self.__engine\n",
    "        try:\n",
    "            self.__input_organic  = __core._data_preparation__input_organic\n",
    "            self.__measurementids_organic = __core._data_preparation__input_organic.copy()\n",
    "            self.__measurementids_organic[['coreid','compositedepth']] = self.__measurementids_organic['measurementid'].str.split(' ', n = 1, expand = True)\n",
    "            self.__measurementids_organic = self.__measurementids_organic[['measurementid','coreid','compositedepth']]\n",
    "            self.__measurementids_organic['compositedepth'].replace(regex=True,inplace=True,to_replace=(r'_duplicate'+r'\\d'),value=r'')\n",
    "            #self.__measurementids_organic = self.__measurementids_organic[~(self.__measurementids_organic['compositedepth'].str.contains(pat = 'duplicate')== True)]\n",
    "            try:\n",
    "                __con = __engine.connect()\n",
    "                self.__measurement_organic_duplicate_check = pd.merge(self.__measurementids_organic, pd.read_sql('measurement', __con), how ='inner', on = ['measurementid', 'coreid'])\n",
    "                self.__measurement_organic_duplicate_check = self.__measurement_organic_duplicate_check.drop(columns = 'compositedepth_y')\n",
    "                self.__measurement_organic_duplicate_check = self.__measurement_organic_duplicate_check.rename(columns = {'compositedepth_x':'compositedepth'})\n",
    "                self.__measurementids_organic = self.__measurementids_organic.append(self.__measurement_organic_duplicate_check).drop_duplicates(keep=False)\n",
    "                self.__measurementids_organic.to_sql('measurement', __con, if_exists='append', index = False)\n",
    "            except IntegrityError:\n",
    "                raise Except(f'There is a problem with core {__coreid}')\n",
    "            finally:\n",
    "                self.__input_organic.to_sql('organic', __con, if_exists='append', index = False)\n",
    "                __con.close()\n",
    "                print (f'I am done with core {__coreid}')\n",
    "        except IntegrityError:   \n",
    "            print (f'I had an integrity error for {__coreid} - It seemes that organic data was already uploaded.')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def run_data_upload(self):\n",
    "        self.__upload_scientist__()\n",
    "        self.__upload_expedition__()\n",
    "        self.__upload_lake__()\n",
    "        self.__upload_drilling__()\n",
    "        if self.__upload_stop == False:\n",
    "            self.__upload_participant__()\n",
    "            self.__upload_organic__()\n",
    "        else:\n",
    "            print('Okokokok - I stop now!')\n",
    "        # finally:\n",
    "        #  del con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scientist(s) already exist!\n",
      "Expedition already exists!\n",
      "Lake already exists!\n",
      "Core PG1111 already exists!\n",
      "Participant(s) already registered!\n",
      "I am done with core PG1111\n"
     ]
    }
   ],
   "source": [
    "#%timeit -n 1 -r 1 \n",
    "###Start###\n",
    "core = data_preparation(filename = 'E:\\ARCLAKES-STANDARDIZED\\PG1111_raw_data.xlsx', suppress_message = True)\n",
    "###Prep###\n",
    "core.run_data_prep()\n",
    "###Check###\n",
    "#check = data_check(core)\n",
    "#check.check_completeness()\n",
    "###Upload###\n",
    "upload = connection_db(core, db = 'MAYHEM', password = 'BoBoBernini', force_upload = True)\n",
    "upload.run_data_upload()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {},
   "outputs": [],
   "source": [
    "organic = core._data_preparation__input_organic.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 410,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>6</th>\n",
       "      <th>measurementid</th>\n",
       "      <th>tn</th>\n",
       "      <th>tc</th>\n",
       "      <th>toc</th>\n",
       "      <th>d13c</th>\n",
       "      <th>water_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>PG1111 0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-24.8</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PG1111 0.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.75</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>PG1111 1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.87</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>PG1111 1.5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>PG1111 2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.76</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>PG1111 1105</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-23.9</td>\n",
       "      <td>56.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>PG1111 1106</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>PG1111 1107</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>PG1111 1108</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>52.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>PG1111 1110</td>\n",
       "      <td>0.007</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.118</td>\n",
       "      <td>NaN</td>\n",
       "      <td>53.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>875 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "6   measurementid     tn   tc    toc   d13c water_content\n",
       "7        PG1111 0    NaN  NaN    NaN  -24.8           NaN\n",
       "8      PG1111 0.5    NaN  NaN    NaN -25.75           NaN\n",
       "9        PG1111 1    NaN  NaN    NaN -25.87           NaN\n",
       "10     PG1111 1.5    NaN  NaN    NaN  -25.5           NaN\n",
       "11       PG1111 2    NaN  NaN    NaN -25.76           NaN\n",
       "..            ...    ...  ...    ...    ...           ...\n",
       "877   PG1111 1105    NaN  NaN    NaN  -23.9         56.04\n",
       "878   PG1111 1106    NaN  NaN    NaN    NaN          51.1\n",
       "879   PG1111 1107    NaN  NaN    NaN    NaN         52.25\n",
       "880   PG1111 1108    NaN  NaN    NaN    NaN         52.24\n",
       "881   PG1111 1110  0.007  NaN  0.118    NaN         53.72\n",
       "\n",
       "[875 rows x 6 columns]"
      ]
     },
     "execution_count": 410,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "organic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
